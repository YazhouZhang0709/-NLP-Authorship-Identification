{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Related Libraries for Text Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import glob\n",
    "import os\n",
    "import operator\n",
    "import textwrap\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.cluster.vq import whiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data\n",
    "### 10 English books with labels from 0~9 (can be found in the folders)\n",
    "###  Book Labels, Book Names and Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Label | Book | Author |\n",
    "| ---- | ---- | ---- |\n",
    "| 0 | A Tale of Two Cities | Charles Dickens |\n",
    "| 1 | Meditations | Marcus Aurelius |\n",
    "| 2 | Dracula | Bram Stoker |\n",
    "| 3 | Grimms' Fairy Tales | Grimm brothers |\n",
    "| 4 | The Practice and Science of Drawing | Harold Speed |\n",
    "| 5 | Pride and Prejudice | Jane Austen |\n",
    "| 6 | Beyond Good and Evil | Friedrich Nietzsche |\n",
    "| 7 | Dubliners | James Joyce |\n",
    "| 8 | The Souls of Black Folk | W. E. B. Du Bois |\n",
    "| 9 | The Picture of Dorian Gray | Oscar Wilde |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Create a dictionary for the final prediction\n",
    "Book_dict={0:\"Charles Dickens\", 1:\"Marcus Aurelius\", 2:\"Bram Stoker\",\n",
    "           3:\"Grimm brothers\", 4:\"Harold Speed\", 5:\"Jane Austen\",\n",
    "           6:\"Friedrich Nietzsche\", 7:\"James Joyce\", 8:\"W. E. B. Du Bois\", 9:\"Oscar Wilde\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From these 10 books, here I pick every 2000 strings as one sample, attached with the corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\$0$ A_Tale_of_Two_Cities.txt\n",
      "Data\\$1$ Meditations.txt\n",
      "Data\\$2$ Dracula.txt\n",
      "Data\\$3$ Grimms'_Fairy_Tales.txt\n",
      "Data\\$4$ The_Practice_and_Science_of_Drawing.txt\n",
      "Data\\$5$ Pride_and_prejudice.txt\n",
      "Data\\$6$ Beyond_Good_And_Evil.txt\n",
      "Data\\$7$ Dubliners.txt\n",
      "Data\\$8$ The_Souls_of_Black_Folk.txt\n",
      "Data\\$9$ The_Picture_of_Dorian_Gray.txt\n"
     ]
    }
   ],
   "source": [
    "# Create a list of sample labels representing the authorships\n",
    "sample_labels=[] \n",
    "# Create a list of samples\n",
    "samples = []\n",
    "# Load data from the folder\n",
    "files = glob.glob(os.path.join(\"Data\", \"*.txt\"))\n",
    "for fn in files:\n",
    "    with open(fn, encoding=\"utf8\") as f:\n",
    "            print(fn)\n",
    "            for segment in textwrap.wrap(f.read().replace('\\n',' '),2000):\n",
    "                samples.append(segment)\n",
    "                sample_labels.append(int(fn.split('$')[1]))\n",
    "all_text = ''.join(str(samples))\n",
    "num_samples = len(samples) # 2370 samples in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "## Based on my literature survey and online resource seaching, here we define 3 functions to extract different features from the text segments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lexical and Punctuation features\n",
    "- ### Lexical features:\n",
    "    - #### The average number of words per sentence\n",
    "    - #### Sentence length variation\n",
    "    - #### Lexical diversity, which is a measure of the richness of the authorâ€™s vocabulary\n",
    "- ### Punctuation features:\n",
    "    - #### Average number of commas, semicolons and colons etc. per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "word_tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def Lexical_Punctuation(data):\n",
    "    # Creatte feature vector           \n",
    "    fvs_lexical = np.zeros((len(data),3), np.float64)\n",
    "    fvs_punct = np.zeros((len(data),5), np.float64)\n",
    "    for e, ch_text in enumerate(data):\n",
    "        # note: the nltk.word_tokenize includes punctuation\n",
    "        tokens = nltk.word_tokenize(ch_text.lower())\n",
    "        words = word_tokenizer.tokenize(ch_text.lower()) # words without punctuation\n",
    "        sentences = sentence_tokenizer.tokenize(ch_text)\n",
    "        vocab = set(words)\n",
    "        words_per_sentence = np.array([len(word_tokenizer.tokenize(s))\n",
    "                                       for s in sentences])\n",
    "\n",
    "        # average number of words per sentence\n",
    "        fvs_lexical[e, 0] = words_per_sentence.mean()\n",
    "        # sentence length variation\n",
    "        fvs_lexical[e, 1] = words_per_sentence.std()\n",
    "        # Lexical diversity\n",
    "        fvs_lexical[e, 2] = len(vocab) / float(len(words))\n",
    "\n",
    "        # Commas per sentence\n",
    "        fvs_punct[e, 0] = tokens.count(',') / float(len(sentences))\n",
    "        # Semicolons per sentence\n",
    "        fvs_punct[e, 1] = tokens.count(';') / float(len(sentences))\n",
    "        # Colons per sentence\n",
    "        fvs_punct[e, 2] = tokens.count(':') / float(len(sentences))\n",
    "        # Question marks per sentence\n",
    "        fvs_punct[e, 3] = tokens.count('?') / float(len(sentences))\n",
    "        # Question marks per sentence\n",
    "        fvs_punct[e, 4] = tokens.count('\"') / float(len(sentences))\n",
    "        \n",
    "    # apply whitening to decorrelate the features\n",
    "    fvs_lexical = whiten(fvs_lexical)\n",
    "    fvs_punct = whiten(fvs_punct)\n",
    "    \n",
    "    return fvs_lexical, fvs_punct\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bag of Words features\n",
    "###   Bag of words represents the frequencies of different words in each chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most common words in all books\n",
    "NUM_TOP_WORDS = 10\n",
    "all_tokens = nltk.word_tokenize(all_text)\n",
    "fdist = nltk.FreqDist(all_tokens)\n",
    "vocab = sorted(fdist.items(), key=operator.itemgetter(1),reverse=True) \n",
    "vocab = list(dict(vocab).keys())[:NUM_TOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn to create the bag for words feature vector for each chapter\n",
    "vectorizer = CountVectorizer(vocabulary=vocab, tokenizer=nltk.word_tokenize)\n",
    "\n",
    "def Bag_of_words(data):\n",
    "    fvs_bow = vectorizer.fit_transform(data).toarray().astype(np.float64)\n",
    "    # normalise by dividing each row by its Euclidean norm\n",
    "    fvs_bow /= np.c_[np.apply_along_axis(np.linalg.norm, 1, fvs_bow)]\n",
    "    return fvs_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Synthetic Features\n",
    "###   For the last feature, here I extract syntactic features of the text. Part of speech (POS) is a classification of each token into a lexical category (e.g. noun). NLTK has a function for POS labeling, and our feature vector is comprised of frequencies for the most common POS tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get part of speech for each token in each chapter\n",
    "def token_to_pos(ch):\n",
    "    tokens = nltk.word_tokenize(ch)\n",
    "    return [p[1] for p in nltk.pos_tag(tokens)]\n",
    "\n",
    "def Synthetic_features(data):\n",
    "    data_pos = [token_to_pos(ch) for ch in data]\n",
    "\n",
    "    # count frequencies for common POS types\n",
    "    pos_list = ['NN', 'NNP', 'DT', 'IN', 'JJ', 'NNS']\n",
    "    fvs_syntax = np.array([[ch.count(pos) for pos in pos_list]\n",
    "                           for ch in data_pos]).astype(np.float64)\n",
    "\n",
    "    # normalise by dividing each row by number of tokens in the books\n",
    "    fvs_syntax /= np.c_[np.array([len(ch) for ch in data_pos])]\n",
    "    \n",
    "    return fvs_syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning: MLP/SVM/KNN/RandomForest based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "##   Build a classifier and then train and test it\n",
    "def Author_Predictor_SVM(fvs_train, fvs_test, y_train):\n",
    "    svcm = SVC()\n",
    "    svcm.fit(fvs_train,y_train)\n",
    "    return svcm.predict(fvs_test)\n",
    "\n",
    "def Author_Predictor_MLP(fvs_train, fvs_test, y_train):\n",
    "    MLP = MLPClassifier(hidden_layer_sizes=(120, ),max_iter=200)\n",
    "    MLP.fit(fvs_train,y_train)\n",
    "    if fold_n == 3:\n",
    "        filename = 'MLP_model.sav'\n",
    "        pickle.dump(MLP, open(filename, 'wb'))\n",
    "    return MLP.predict(fvs_test)\n",
    "\n",
    "def Author_Predictor_RF(fvs_train, fvs_test, y_train):\n",
    "    rf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=15)\n",
    "    rf.fit(fvs_train,y_train)\n",
    "    return rf.predict(fvs_test)\n",
    "\n",
    "def Author_Predictor_KNN(fvs_train, fvs_test, y_train):\n",
    "    KNN = KNeighborsClassifier(20)\n",
    "    KNN.fit(fvs_train,y_train)\n",
    "    return KNN.predict(fvs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing data split Using 5-fold Cross Validation here\n",
    "### 5 different splits of data set, in each split :80% for training, remaining 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\vq.py:141: RuntimeWarning: Some columns have standard deviation zero. The values of these columns will not change.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************Result for Fold 1***************************************\n",
      "The test accuracy for Fold 1 is  0.5675182481751825\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "    Charles Dickens       0.36      0.86      0.51        78\n",
      "    Marcus Aurelius       1.00      0.19      0.32        42\n",
      "        Bram Stoker       0.62      0.15      0.24        87\n",
      "     Grimm brothers       0.91      0.73      0.81        55\n",
      "       Harold Speed       0.79      0.59      0.68        46\n",
      "        Jane Austen       0.65      0.48      0.55        71\n",
      "Friedrich Nietzsche       0.44      0.68      0.54        41\n",
      "        James Joyce       0.95      0.51      0.67        39\n",
      "   W. E. B. Du Bois       0.41      0.74      0.52        43\n",
      "        Oscar Wilde       0.85      0.76      0.80        46\n",
      "\n",
      "        avg / total       0.67      0.55      0.54       548\n",
      "\n",
      "[[68  0  0  0  1  1  6  0  1  1]\n",
      " [ 6 12  0  0  0  7 10  0  7  0]\n",
      " [47  0 13  0  2  6  0  0 17  2]\n",
      " [ 9  0  0 44  0  0  1  1  0  0]\n",
      " [ 5  0  0  0 26  3  2  2  6  2]\n",
      " [32  0  1  0  0 30  6  0  1  1]\n",
      " [ 4  0  0  0  0  2 30  1  3  1]\n",
      " [ 2  0  5  1  3  0  0 15  9  4]\n",
      " [ 7  0  0  0  1  0  2  0 33  0]\n",
      " [ 6  0  0  0  1  1  1  0  0 37]]\n",
      " \n",
      "***************************Result for Fold 1***************************************\n",
      " \n",
      "***************************Result for Fold 2***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy for Fold 2 is  0.7380952380952381\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "    Charles Dickens       0.59      0.71      0.64        78\n",
      "    Marcus Aurelius       0.89      0.60      0.71        42\n",
      "        Bram Stoker       0.88      0.41      0.56        87\n",
      "     Grimm brothers       0.81      0.94      0.87        54\n",
      "       Harold Speed       0.81      0.85      0.83        46\n",
      "        Jane Austen       0.62      0.94      0.75        71\n",
      "Friedrich Nietzsche       0.54      0.71      0.61        41\n",
      "        James Joyce       0.78      0.74      0.76        39\n",
      "   W. E. B. Du Bois       0.60      0.36      0.45        42\n",
      "        Oscar Wilde       0.83      0.87      0.85        46\n",
      "\n",
      "        avg / total       0.73      0.71      0.70       546\n",
      "\n",
      "[[52  0  0  2  2 15  4  0  3  0]\n",
      " [ 5 28  1  1  0  2  4  0  1  0]\n",
      " [16  0 42  4  1 16  0  3  2  3]\n",
      " [ 1  0  0 52  0  0  0  0  1  0]\n",
      " [ 0  0  1  1 40  1  1  2  0  0]\n",
      " [ 2  0  0  0  0 66  3  0  0  0]\n",
      " [ 1  3  0  0  0  3 29  1  1  3]\n",
      " [ 2  0  2  0  1  0  0 33  1  0]\n",
      " [ 6  0  0  0  0  5 12  0 19  0]\n",
      " [ 3  0  1  0  0  0  0  2  1 39]]\n",
      " \n",
      "***************************Result for Fold 2***************************************\n",
      " \n"
     ]
    }
   ],
   "source": [
    "samples = np.array(samples)\n",
    "sample_labels = np.array(sample_labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "accuracy_result = []\n",
    "classification_report_result = []\n",
    "confusion_matrix_result = []\n",
    "target_names = [Book_dict[i] for i in range(10)]\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "fold_n = 0\n",
    "for train_index, test_index in skf.split(samples, sample_labels):\n",
    "    X_train, X_test = samples[train_index],samples[test_index]\n",
    "    y_train, y_test = sample_labels[train_index], sample_labels[test_index]\n",
    "    \n",
    "    # Here we concatenate all these four different feature vectors together to get the final feature vectors\n",
    "    # Feature vectors for training\n",
    "    train_fvs = np.hstack((Lexical_Punctuation(X_train)[0],Lexical_Punctuation(X_train)[1], Bag_of_words(X_train), Synthetic_features(X_train)))\n",
    "    # Feature vectors for testing\n",
    "    test_fvs = np.hstack((Lexical_Punctuation(X_test)[0],Lexical_Punctuation(X_test)[1], Bag_of_words(X_test), Synthetic_features(X_test)))\n",
    "    \n",
    "    # Show the 5 fold validation results of our model\n",
    "    fold_n += 1\n",
    "    print(\"***************************\"+\"Result for Fold \"+str(fold_n)+\"***************************************\")\n",
    "    acc = accuracy_score(y_test, Author_Predictor_MLP(train_fvs, test_fvs, y_train))\n",
    "    print(\"The test accuracy for Fold \"+str(fold_n)+\" is \", acc)\n",
    "    accuracy_result.append(acc)\n",
    "    cla_report = classification_report(y_test, Author_Predictor_MLP(train_fvs, test_fvs, y_train), target_names = target_names )\n",
    "    print(cla_report)\n",
    "    classification_report_result.append(cla_report)\n",
    "    con_matrix = confusion_matrix(y_test, Author_Predictor_MLP(train_fvs, test_fvs, y_train))\n",
    "    print(con_matrix)\n",
    "    confusion_matrix_result.append(con_matrix)\n",
    "    print(' ')\n",
    "    print(\"***************************\"+\"Result for Fold \"+str(fold_n)+\"***************************************\")\n",
    "    print(' ')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuracy = np.mean(accuracy_result)\n",
    "print(\"The average accuracy of the test data is:\", avg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the authorship of a text segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a text segment from one of these 10 books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_segment = [samples[666]]\n",
    "print(text_segment)\n",
    "print(sample_labels[666])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the saved model and predict the authorship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = pickle.load(open('MLP_model.sav', 'rb'))\n",
    "\n",
    "# Feature vectors for testing\n",
    "LP1, LP2 = Lexical_Punctuation(text_segment)\n",
    "ts_fvs = np.hstack((LP1 ,LP2 , Bag_of_words(text_segment), Synthetic_features(text_segment)))\n",
    "\n",
    "# prediction\n",
    "result = MLP.predict(ts_fvs)\n",
    "print(\"This segment of text belongs to the author of :\",result, Book_dict[result[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
