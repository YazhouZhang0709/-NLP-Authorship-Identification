{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Related Libraries for Text Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import glob\n",
    "import os\n",
    "import operator\n",
    "import textwrap\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.cluster.vq import whiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data\n",
    "### 10 English books with labels from 0~9 (can be found in the folders)\n",
    "###  Book Labels, Book Names and Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Label | Book | Author |\n",
    "| ---- | ---- | ---- |\n",
    "| 0 | A Tale of Two Cities | Charles Dickens |\n",
    "| 1 | Meditations | Marcus Aurelius |\n",
    "| 2 | Dracula | Bram Stoker |\n",
    "| 3 | Grimms' Fairy Tales | Grimm brothers |\n",
    "| 4 | The Practice and Science of Drawing | Harold Speed |\n",
    "| 5 | Pride and Prejudice | Jane Austen |\n",
    "| 6 | Beyond Good and Evil | Friedrich Nietzsche |\n",
    "| 7 | Dubliners | James Joyce |\n",
    "| 8 | The Souls of Black Folk | W. E. B. Du Bois |\n",
    "| 9 | The Picture of Dorian Gray | Oscar Wilde |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Create a dictionary for the final prediction\n",
    "Book_dict={0:\"Charles Dickens\", 1:\"Marcus Aurelius\", 2:\"Bram Stoker\",\n",
    "           3:\"Grimm brothers\", 4:\"Harold Speed\", 5:\"Jane Austen\",\n",
    "           6:\"Friedrich Nietzsche\", 7:\"James Joyce\", 8:\"W. E. B. Du Bois\", 9:\"Oscar Wilde\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From these 10 books, here I pick every 2000 strings as one sample, attached with the corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\$0$ A_Tale_of_Two_Cities.txt\n",
      "Data\\$1$ Meditations.txt\n",
      "Data\\$2$ Dracula.txt\n",
      "Data\\$3$ Grimms'_Fairy_Tales.txt\n",
      "Data\\$4$ The_Practice_and_Science_of_Drawing.txt\n",
      "Data\\$5$ Pride_and_prejudice.txt\n",
      "Data\\$6$ Beyond_Good_And_Evil.txt\n",
      "Data\\$7$ Dubliners.txt\n",
      "Data\\$8$ The_Souls_of_Black_Folk.txt\n",
      "Data\\$9$ The_Picture_of_Dorian_Gray.txt\n"
     ]
    }
   ],
   "source": [
    "# Create a list of sample labels representing the authorships\n",
    "sample_labels=[] \n",
    "# Create a list of samples\n",
    "samples = []\n",
    "# Load data from the folder\n",
    "files = glob.glob(os.path.join(\"Data\", \"*.txt\"))\n",
    "for fn in files:\n",
    "    with open(fn, encoding=\"utf8\") as f:\n",
    "            print(fn)\n",
    "            for segment in textwrap.wrap(f.read().replace('\\n',' '),2000):\n",
    "                samples.append(segment)\n",
    "                sample_labels.append(int(fn.split('$')[1]))\n",
    "all_text = ''.join(str(samples))\n",
    "num_samples = len(samples) # 2370 samples in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "## Based on my literature survey and online resource seaching, here we define 3 functions to extract different features from the text segments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lexical and Punctuation features\n",
    "- ### Lexical features:\n",
    "    - #### The average number of words per sentence\n",
    "    - #### Sentence length variation\n",
    "    - #### Lexical diversity, which is a measure of the richness of the author’s vocabulary\n",
    "- ### Punctuation features:\n",
    "    - #### Average number of commas, semicolons and colons etc. per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "word_tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def Lexical_Punctuation(data):\n",
    "    # Creatte feature vector           \n",
    "    fvs_lexical = np.zeros((len(data),3), np.float64)\n",
    "    fvs_punct = np.zeros((len(data),5), np.float64)\n",
    "    for e, ch_text in enumerate(data):\n",
    "        # note: the nltk.word_tokenize includes punctuation\n",
    "        tokens = nltk.word_tokenize(ch_text.lower())\n",
    "        words = word_tokenizer.tokenize(ch_text.lower()) # words without punctuation\n",
    "        sentences = sentence_tokenizer.tokenize(ch_text)\n",
    "        vocab = set(words)\n",
    "        words_per_sentence = np.array([len(word_tokenizer.tokenize(s))\n",
    "                                       for s in sentences])\n",
    "\n",
    "        # average number of words per sentence\n",
    "        fvs_lexical[e, 0] = words_per_sentence.mean()\n",
    "        # sentence length variation\n",
    "        fvs_lexical[e, 1] = words_per_sentence.std()\n",
    "        # Lexical diversity\n",
    "        fvs_lexical[e, 2] = len(vocab) / float(len(words))\n",
    "\n",
    "        # Commas per sentence\n",
    "        fvs_punct[e, 0] = tokens.count(',') / float(len(sentences))\n",
    "        # Semicolons per sentence\n",
    "        fvs_punct[e, 1] = tokens.count(';') / float(len(sentences))\n",
    "        # Colons per sentence\n",
    "        fvs_punct[e, 2] = tokens.count(':') / float(len(sentences))\n",
    "        # Question marks per sentence\n",
    "        fvs_punct[e, 3] = tokens.count('?') / float(len(sentences))\n",
    "        # Question marks per sentence\n",
    "        fvs_punct[e, 4] = tokens.count('\"') / float(len(sentences))\n",
    "    # apply whitening to decorrelate the features\n",
    "    fvs_lexical = whiten(fvs_lexical)\n",
    "    fvs_punct = whiten(fvs_punct)\n",
    "    \n",
    "    return fvs_lexical, fvs_punct\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bag of Words features\n",
    "###   Bag of words represents the frequencies of different words in each chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most common words in all books\n",
    "NUM_TOP_WORDS = 10\n",
    "all_tokens = nltk.word_tokenize(all_text)\n",
    "fdist = nltk.FreqDist(all_tokens)\n",
    "vocab = sorted(fdist.items(), key=operator.itemgetter(1),reverse=True) \n",
    "vocab = list(dict(vocab).keys())[:NUM_TOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn to create the bag for words feature vector for each chapter\n",
    "vectorizer = CountVectorizer(vocabulary=vocab, tokenizer=nltk.word_tokenize)\n",
    "\n",
    "def Bag_of_words(data):\n",
    "    fvs_bow = vectorizer.fit_transform(data).toarray().astype(np.float64)\n",
    "    # normalise by dividing each row by its Euclidean norm\n",
    "    fvs_bow /= np.c_[np.apply_along_axis(np.linalg.norm, 1, fvs_bow)]\n",
    "    return fvs_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Synthetic Features\n",
    "###   For the last feature, here I extract syntactic features of the text. Part of speech (POS) is a classification of each token into a lexical category (e.g. noun). NLTK has a function for POS labeling, and our feature vector is comprised of frequencies for the most common POS tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get part of speech for each token in each chapter\n",
    "def token_to_pos(ch):\n",
    "    tokens = nltk.word_tokenize(ch)\n",
    "    return [p[1] for p in nltk.pos_tag(tokens)]\n",
    "\n",
    "def Synthetic_features(data):\n",
    "    data_pos = [token_to_pos(ch) for ch in data]\n",
    "\n",
    "    # count frequencies for common POS types\n",
    "    pos_list = ['NN', 'NNP', 'DT', 'IN', 'JJ', 'NNS']\n",
    "    fvs_syntax = np.array([[ch.count(pos) for pos in pos_list]\n",
    "                           for ch in data_pos]).astype(np.float64)\n",
    "\n",
    "    # normalise by dividing each row by number of tokens in the books\n",
    "    fvs_syntax /= np.c_[np.array([len(ch) for ch in data_pos])]\n",
    "    \n",
    "    return fvs_syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning: MLP/SVM/KNN/RandomForest based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "##   Build a classifier and then vote for \n",
    "def Author_Predictor_SVM(fvs_train, fvs_test, y_train):\n",
    "    svcm = SVC()\n",
    "    svcm.fit(fvs_train,y_train)\n",
    "    return svcm.predict(fvs_test)\n",
    "\n",
    "def Author_Predictor_MLP(fvs_train, fvs_test, y_train):\n",
    "    MLP = MLPClassifier(hidden_layer_sizes=(150, ),max_iter=200)\n",
    "    MLP.fit(fvs_train,y_train)\n",
    "    return MLP.predict(fvs_test)\n",
    "\n",
    "def Author_Predictor_RF(fvs_train, fvs_test, y_train):\n",
    "    rf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=15)\n",
    "    rf.fit(fvs_train,y_train)\n",
    "    return rf.predict(fvs_test)\n",
    "\n",
    "def Author_Predictor_KNN(fvs_train, fvs_test, y_train):\n",
    "    KNN = KNeighborsClassifier(20)\n",
    "    KNN.fit(fvs_train,y_train)\n",
    "    return KNN.predict(fvs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing data split Using 5-fold Cross Validation here\n",
    "### 5 different splits of data set, in each split :80% for training, remaining 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\vq.py:141: RuntimeWarning: Some columns have standard deviation zero. The values of these columns will not change.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************Result for Fold 1***************************************\n",
      "The test accuracy for Fold1is 0.5638686131386861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "    Charles Dickens       0.39      0.83      0.53        78\n",
      "    Marcus Aurelius       0.93      0.33      0.49        42\n",
      "        Bram Stoker       0.65      0.17      0.27        87\n",
      "     Grimm brothers       0.95      0.76      0.85        55\n",
      "       Harold Speed       0.74      0.54      0.62        46\n",
      "        Jane Austen       0.62      0.56      0.59        71\n",
      "Friedrich Nietzsche       0.51      0.76      0.61        41\n",
      "        James Joyce       0.79      0.49      0.60        39\n",
      "   W. E. B. Du Bois       0.42      0.70      0.52        43\n",
      "        Oscar Wilde       0.84      0.78      0.81        46\n",
      "\n",
      "        avg / total       0.67      0.58      0.57       548\n",
      "\n",
      "[[63  0  0  1  2  3  6  0  2  1]\n",
      " [ 4 11  2  0  0  9 11  0  5  0]\n",
      " [42  0 22  0  2  7  0  0 12  2]\n",
      " [ 8  0  0 47  0  0  0  0  0  0]\n",
      " [ 2  0  0  1 28  3  2  2  5  3]\n",
      " [19  0  1  1  0 44  4  0  1  1]\n",
      " [ 8  0  0  1  2  2 23  1  4  0]\n",
      " [ 0  0  9  1  4  1  0 16  5  3]\n",
      " [ 7  0  0  0  1  2  2  0 31  0]\n",
      " [ 6  0  0  0  0  2  0  0  0 38]]\n",
      " \n",
      "***************************Result for Fold 1***************************************\n",
      " \n",
      "***************************Result for Fold 2***************************************\n",
      "The test accuracy for Fold2is 0.7051282051282052\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "    Charles Dickens       0.60      0.68      0.64        78\n",
      "    Marcus Aurelius       1.00      0.48      0.65        42\n",
      "        Bram Stoker       0.88      0.41      0.56        87\n",
      "     Grimm brothers       0.79      0.96      0.87        54\n",
      "       Harold Speed       0.95      0.83      0.88        46\n",
      "        Jane Austen       0.55      0.99      0.70        71\n",
      "Friedrich Nietzsche       0.64      0.71      0.67        41\n",
      "        James Joyce       0.80      0.90      0.84        39\n",
      "   W. E. B. Du Bois       0.76      0.52      0.62        42\n",
      "        Oscar Wilde       0.89      0.87      0.88        46\n",
      "\n",
      "        avg / total       0.77      0.72      0.71       546\n",
      "\n",
      "[[52  0  0  2  2 14  4  0  4  0]\n",
      " [ 8 25  1  0  0  1  6  0  1  0]\n",
      " [16  3 30  4  2 19  0  4  6  3]\n",
      " [ 4  0  0 49  0  0  0  0  1  0]\n",
      " [ 1  0  0  1 41  0  0  2  1  0]\n",
      " [ 2  0  0  0  0 65  4  0  0  0]\n",
      " [ 0  2  0  0  0  4 30  1  1  3]\n",
      " [ 2  0  0  0  3  0  0 31  3  0]\n",
      " [ 2  0  0  0  1  2 11  0 25  1]\n",
      " [ 2  0  1  0  0  0  0  0  1 42]]\n",
      " \n",
      "***************************Result for Fold 2***************************************\n",
      " \n",
      "***************************Result for Fold 3***************************************\n",
      "The test accuracy for Fold3is 0.7371323529411765\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "    Charles Dickens       0.55      0.83      0.66        78\n",
      "    Marcus Aurelius       0.84      0.86      0.85        42\n",
      "        Bram Stoker       0.81      0.69      0.75        87\n",
      "     Grimm brothers       0.85      0.98      0.91        54\n",
      "       Harold Speed       0.67      0.87      0.75        46\n",
      "        Jane Austen       0.89      0.55      0.68        71\n",
      "Friedrich Nietzsche       0.72      0.53      0.61        40\n",
      "        James Joyce       0.76      0.64      0.69        39\n",
      "   W. E. B. Du Bois       0.72      0.86      0.78        42\n",
      "        Oscar Wilde       0.93      0.62      0.75        45\n",
      "\n",
      "        avg / total       0.77      0.74      0.74       544\n",
      "\n",
      "[[57  0  3  4  1  1  2  1  9  0]\n",
      " [ 3 33  4  0  0  0  2  0  0  0]\n",
      " [ 7  4 67  1  4  1  0  2  1  0]\n",
      " [ 0  0  1 53  0  0  0  0  0  0]\n",
      " [ 1  0  1  0 41  1  0  2  0  0]\n",
      " [17  0 10  1  1 35  1  1  5  0]\n",
      " [ 7  1  0  5  4  1 20  0  2  0]\n",
      " [ 5  0  6  0  4  0  0 24  0  0]\n",
      " [ 1  0  1  0  2  0  1  0 37  0]\n",
      " [ 3  0  0  0  7  0  3  2  3 27]]\n",
      " \n",
      "***************************Result for Fold 3***************************************\n",
      " \n",
      "***************************Result for Fold 4***************************************\n",
      "The test accuracy for Fold4is 0.7361623616236163\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "    Charles Dickens       0.54      0.69      0.61        78\n",
      "    Marcus Aurelius       0.86      0.76      0.81        42\n",
      "        Bram Stoker       0.80      0.68      0.73        87\n",
      "     Grimm brothers       0.95      0.78      0.86        54\n",
      "       Harold Speed       0.75      0.91      0.82        45\n",
      "        Jane Austen       0.84      0.74      0.79        70\n",
      "Friedrich Nietzsche       0.56      0.93      0.70        40\n",
      "        James Joyce       0.80      0.62      0.70        39\n",
      "   W. E. B. Du Bois       0.67      0.62      0.64        42\n",
      "        Oscar Wilde       0.89      0.69      0.78        45\n",
      "\n",
      "        avg / total       0.76      0.73      0.74       542\n",
      "\n",
      "[[62  2  3  0  0  3  5  0  3  0]\n",
      " [ 4 31  2  0  1  0  3  0  0  1]\n",
      " [ 9  1 59  2  4  4  0  2  5  1]\n",
      " [ 9  0  0 44  0  0  1  0  0  0]\n",
      " [ 1  1  1  0 42  0  0  0  0  0]\n",
      " [14  0  5  0  0 49  2  0  0  0]\n",
      " [ 2  0  0  0  0  0 37  0  1  0]\n",
      " [ 5  0  2  1  3  0  2 24  0  2]\n",
      " [ 7  0  0  0  6  0  8  0 21  0]\n",
      " [ 3  1  2  0  0  1  2  2  2 32]]\n",
      " \n",
      "***************************Result for Fold 4***************************************\n",
      " \n",
      "***************************Result for Fold 5***************************************\n",
      "The test accuracy for Fold5is 0.48333333333333334\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "    Charles Dickens       0.62      0.21      0.31        77\n",
      "    Marcus Aurelius       0.11      0.12      0.11        42\n",
      "        Bram Stoker       0.41      0.79      0.54        86\n",
      "     Grimm brothers       0.91      0.72      0.80        54\n",
      "       Harold Speed       0.34      0.62      0.44        45\n",
      "        Jane Austen       0.90      0.40      0.55        70\n",
      "Friedrich Nietzsche       0.24      0.10      0.14        40\n",
      "        James Joyce       0.41      0.67      0.50        39\n",
      "   W. E. B. Du Bois       1.00      0.05      0.09        42\n",
      "        Oscar Wilde       0.58      0.78      0.67        45\n",
      "\n",
      "        avg / total       0.57      0.46      0.44       540\n",
      "\n",
      "[[18  5 34  2  6  0  1  4  0  7]\n",
      " [ 0  6 19  0  8  1  0  3  0  5]\n",
      " [ 0 10 64  0  7  1  1  3  0  0]\n",
      " [ 1  0  1 42  6  0  1  2  1  0]\n",
      " [ 1  2  3  0 30  0  4  4  0  1]\n",
      " [ 5  4 24  0  6 25  0  3  0  3]\n",
      " [ 3 22  1  0  6  0  5  3  0  0]\n",
      " [ 1  2  2  0  7  0  1 24  0  2]\n",
      " [ 3  5 14  2  7  0  1  5  4  1]\n",
      " [ 0  0  0  0  7  0  0  3  0 35]]\n",
      " \n",
      "***************************Result for Fold 5***************************************\n",
      " \n"
     ]
    }
   ],
   "source": [
    "samples = np.array(samples)\n",
    "sample_labels = np.array(sample_labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "accuracy_result = []\n",
    "classification_report_result = []\n",
    "confusion_matrix_result = []\n",
    "target_names = [Book_dict[i] for i in range(10)]\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "fold_n = 0\n",
    "for train_index, test_index in skf.split(samples, sample_labels):\n",
    "    X_train, X_test = samples[train_index],samples[test_index]\n",
    "    y_train, y_test = sample_labels[train_index], sample_labels[test_index]\n",
    "    \n",
    "    # Here we concatenate all these four different feature vectors together to get the final feature vectors\n",
    "    # Feature vectors for training\n",
    "    train_fvs = np.hstack((Lexical_Punctuation(X_train)[0],Lexical_Punctuation(X_train)[1], Bag_of_words(X_train), Synthetic_features(X_train)))\n",
    "    # Feature vectors for testing\n",
    "    test_fvs = np.hstack((Lexical_Punctuation(X_test)[0],Lexical_Punctuation(X_test)[1], Bag_of_words(X_test), Synthetic_features(X_test)))\n",
    "    \n",
    "    # Show the 5 fold validation results of our model\n",
    "    fold_n += 1\n",
    "    print(\"***************************\"+\"Result for Fold \"+str(fold_n)+\"***************************************\")\n",
    "    acc = accuracy_score(y_test, Author_Predictor_MLP(train_fvs, test_fvs, y_train))\n",
    "    print(\"The test accuracy for Fold\"+str(fold_n)+\"is\", acc)\n",
    "    accuracy_result.append(acc)\n",
    "    cla_report = classification_report(y_test, Author_Predictor_MLP(train_fvs, test_fvs, y_train), target_names = target_names )\n",
    "    print(cla_report)\n",
    "    classification_report_result.append(cla_report)\n",
    "    con_matrix = confusion_matrix(y_test, Author_Predictor_MLP(train_fvs, test_fvs, y_train))\n",
    "    print(con_matrix)\n",
    "    confusion_matrix_result.append(con_matrix)\n",
    "    print(' ')\n",
    "    print(\"***************************\"+\"Result for Fold \"+str(fold_n)+\"***************************************\")\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5638686131386861,\n",
       " 0.7051282051282052,\n",
       " 0.7371323529411765,\n",
       " 0.7361623616236163,\n",
       " 0.48333333333333334]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy of the test data is: 0.6451249732330034\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy = np.mean(accuracy_result)\n",
    "print(\"The average accuracy of the test data is:\", avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2720"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the authorship of a text segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a text segment from one of these 10 books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a kind heart, he got off his horse and put the three prisoners back into the water. They leapt with delight, put out their heads, and cried to him: ‘We will remember you and repay you for saving us!’  He rode on, and after a while it seemed to him that he heard a voice in the sand at his feet. He listened, and heard an ant-king complain: ‘Why cannot folks, with their clumsy beasts, keep off our bodies? That stupid horse, with his heavy hoofs, has been treading down my people without mercy!’ So he turned on to a side path and the ant-king cried out to him: ‘We will remember you--one good turn deserves another!’  The path led him into a wood, and there he saw two old ravens standing by their nest, and throwing out their young ones. ‘Out with you, you idle, good-for-nothing creatures!’ cried they; ‘we cannot find food for you any longer; you are big enough, and can provide for yourselves.’ But the poor young ravens lay upon the ground, flapping their wings, and crying: ‘Oh, what helpless chicks we are! We must shift for ourselves, and yet we cannot fly! What can we do, but lie here and starve?’ So the good young fellow alighted and killed his horse with his sword, and gave it to them for food. Then they came hopping up to it, satisfied their hunger, and cried: ‘We will remember you--one good turn deserves another!’  And now he had to use his own legs, and when he had walked a long way, he came to a large city. There was a great noise and crowd in the streets, and a man rode up on horseback, crying aloud: ‘The king’s daughter wants a husband; but whoever seeks her hand must perform a hard task, and if he does not succeed he will forfeit his life.’ Many had already made the attempt, but in vain; nevertheless when the youth saw the king’s daughter he was so overcome by her great beauty that he forgot all danger, went before the king, and declared himself a suitor.  So he was led out to the sea, and a gold ring was thrown into it, before his eyes; then the king ordered him\n"
     ]
    }
   ],
   "source": [
    "text_segment = samples[1179]\n",
    "print(text_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: Mean of empty slice.\n",
      "E:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "E:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "E:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "E:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-3a7c64fc601d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Feature vectors for testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mts_fvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLexical_Punctuation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_segment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLexical_Punctuation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_segment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBag_of_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_segment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSynthetic_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_segment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_fvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1acc0deced62>\u001b[0m in \u001b[0;36mLexical_Punctuation\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mfvs_lexical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords_per_sentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# Lexical diversity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mfvs_lexical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Commas per sentence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# Feature vectors for testing\n",
    "ts_fvs = np.hstack((Lexical_Punctuation(text_segment)[0],Lexical_Punctuation(text_segment)[1], Bag_of_words(text_segment), Synthetic_features(text_segment)))\n",
    "MLP.predict(ts_fvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Author_Predictor_MLP() missing 1 required positional argument: 'y_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-294ed6dd1267>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAuthor_Predictor_MLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_fvs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_fvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: Author_Predictor_MLP() missing 1 required positional argument: 'y_train'"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, Author_Predictor_MLP(train_fvs, test_fvs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [Book_dict[i] for i in range(10)]\n",
    "\n",
    "print(classification_report(y_test, Author_Predictor_MLP(train_fvs, test_fvs), target_names = target_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning: KMeans Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=10, init='k-means++', n_init=10, verbose=0)\n",
    "km.fit(fvs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
